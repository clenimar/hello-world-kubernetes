# python-service

Deploy python-service to a Kubernetes cluster. This Helm chart is autogenerated by `sconify-image`.

### Prerequisites

* A Kubernetes cluster;
* Helm 3;
* Persistent Volume (PV) provisioner support for persistence.

### Install the chart

To install the Helm chart to your Kubernetes cluster, run:

```bash
helm install my-app /path/to/helm-chart
```

This will install the chart with default values. You can customize the installation by setting parameter values using `--set`:

```bash
helm install my-app /path/to/helm-chart \
  --set image=mycr.io/production/my-app:v0.1 \
  --set useSGXDevPlugin=azure
```

The Helm chart uses the default parameters defined in a `values.yaml` file. You can have as many YAML files as you want (for example, one per scenario) and select them via `-f`:

```bash
helm install my-app /path/to/helm-chart \
  -f values-production.yaml
```

For the full list of parameters that this chart supports, please have a look at [Parameters](#parameters).

#### SGX device

This chart supports the SCONE SGX Device Plugin, the Azure SGX Device Plugin (e.g., for AKS), and mounting the SGX driver manually, via volumes (requires privileged mode). You choose between different ways of binding the SGX driver via the parameter `useSGXDevPlugin`, that accepts the values `scone` (default), `azure` and `disabled`.

By default, this Helm chart uses the [SCONE SGX Plugin](https://sconedocs.github.io/helm_sgxdevplugin/), which needs to be installed to your cluster.

Alternatively, set `useSGXDevPlugin` to `azure` (e.g., `--set useSGXDevPlugin=azure`) to support Azure's SGX Device Plugin. Since Azure requires the amount of EPC memory allocated to your application to be specified, the parameter `sgxEpcMem` (SGX EPC memory in MiB) becomes required too (e.g., `--set useSGXDevPlugin=azure --set sgxEpcMem=16`).

In case you do not want to use the SGX plugin, you can `--set useSGXDevPlugin=disabled` and the `/dev/isgx` volume will be mounted into your container as a `hostPath` volume.

Please note that using `useSGXDevPlugin=disabled` requires privileged mode, which will grant your container access to ALL host devices. This is not recommended.

### Parameters

A complete list of parameters this chart supports.

#### Common parameters

|Parameter|Description|Default|
|---|---|---|
`replicaCount`|How many replicas to deploy|`1`
`image`|Workload image|`registry.scontain.com:5050/clenimar/test:python-k8-test-29370`
`imagePullPolicy`|Workload image pull policy|`Always`
`imagePullSecrets`|Workload image pull secrets (to access private registries)|`[]`
`nameOverride`|String to partially override sconify-python-service.fullname template with a string (will prepend the release name)|`nil`
`fullNameOverride`|String to fully override sconify-python-service.fullname template with a string|`nil`


#### SCONE and SGX parameters

|Parameter|Description|Default|
|---|---|---|
`scone.cas`|SCONE CAS address|`5-3-0.scone-cas.cf`
`scone.configID`|SCONE config ID for the workload|`ns-19651751520310/python-session/python-service`
`scone.allowDlOpen`|Value for SCONE_ALLOW_DLOPEN environment variable|`1`
`scone.heap`|Value for SCONE_HEAP environment variable|`256m`
`scone.stack`|Value for SCONE_STACK environment variable|`4m`
`scone.fork`|Value for SCONE_FORK environment variable|`0`
`scone.log`|Value for SCONE_LOG environment variable|`ERROR`
`scone.printVersion`|Print SCONE version information|`false`
`useSGXDevPlugin`|Use [SGX Device Plugin](#sgx-device) to access SGX resources.|`"scone"`
`sgxEpcMem`|Required to Azure SGX Device Plugin. Protected EPC memory in MiB|`4`
`attestationCheck.enabled`|Run the attestation check initContainer to make sure your pods have access to attestation services|`true`
`attestationCheck.image`|Image for attestation check initContainer|`registry.scontain.com:5050/clenimar/attestation-check:latest`

#### Other parameters

|Parameter|Description|Default|
|---|---|---|
`securityContext`|Configure a security context for the pod|`{}`
`extraEnvVars`|Environment variables to be injected into workload container (NOTE: Will have no effect with attestation)|`{}`
`resources`|CPU/Memory resource requests/limits for node.|`{}`
`nodeSelector`|Node labels for pod assignment (this value is evaluated as a template)|`{}`
`tolerations`|List of node taints to tolerate (this value is evaluated as a template)|`[]`
`affinity`|Map of node/pod affinities (The value is evaluated as a template)|`{}`

#### volumev1 persistence parameters

|Parameter|Description|Default|
|---|---|---|
`volumev1.persistence.enabled`|Use PersistentVolumes for storage (a PersistentVolumeClaim will be created). If disabled, use `emptyDir` volumes, and data will be lost when the pod is removed or restarted (i.e., no persistence) |`false`
`volumev1.persistence.storageClass`|If persistence is enabled, set the StorageClass for the new PersistentVolumeClaim|`""`
`volumev1.persistence.existingClaim`|If persistence is enabled, set if you want to use an existing PersistentVolumeClaim rather than creating a new one|`""`
`volumev1.persistence.size`|If persistence is enabled, set the size of the volume being requested via the PersistentVolumeClaim|`1Gi`
`volumev1.persistence.accessMode`|If persistence is enabled, set the, access mode of the volume being requested via the PersistentVolumeClaim|`ReadWriteMany`

